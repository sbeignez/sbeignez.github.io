# Probability course (MIT 6.431x)

MIT 6.431x, Probability, Spring 2022

## A. The course - Syllabus

### Unit 1: Probability models and axioms `[Chapter 1]`
* L1: Probability models and axioms `[1.1 & 1.2]`

### Unit 2: Conditioning and independence `[Chapter 1]`
* L2: Conditioning and Bayes’ rule `[1.3 & 1.4]`
* L3: Independence `[1.5]`

### Unit 3: Counting `[Chapter 1]`
* L4: Counting `[1.6]`

### Unit 4: Discrete random variables `[Chapter 2]`
* L5: Probability mass functions and expectations
* L6: Variance; Conditioning on an event; Multiple r.v.’s
* L7: Conditioning on a random variable; Independence of r.v.’s

### Unit 5: Continuous random variables `[Chapter 3]`
* L8: Probability density functions
* L9: Conditioning on an event; Multiple r.v.’s
* L10: Conditioning on a random variable; Independence; Bayes’ rule

### Unit 6: Further topics on random variables `[Chapter 4]`
* L11: Derived distributions
* L12: Sums of r.v.’s; Covariance and correlation
* L13: Conditional expectation and variance revisited; Sum of a random number of r.v.’s

### Unit 7: Bayesian inference `[Chapter 8]`
* L14: Introduction to Bayesian inference
* L15: Linear models with normal noise
* L16: Least mean squares (LMS) estimation
* L17: Linear least mean squares (LLMS) estimation 

### Unit 8: Limit theorems and classical statistics `[Chapter 5]`
* L18: Inequalities, convergence, and the Weak Law of Large Numbers
* L19: The Central Limit Theorem (CLT)
* L20: An introduction to classical statistics

### Unit 9: Bernoulli and Poisson processes `[Chapter 6]`
* L21: The Bernoulli process `[6.1]`
* L22: The Poisson process `[6.2]`
* L23: More on the Poisson process `[6.2]`

### Unit 10: Markov chains `[Chapter 7]`
* L24: Finite-state Markov chains `[7.1]`
* L25: Steady-state behavior of Markov chains `[7.3]`
* L26: Absorption probabilities and expected time to absorption `[7.4]`


## B. The Book - Table of Content
[Introduction to Probability, 2nd edition, by Bertsekas and Tsitsiklis, Athena Scientific, 2008](http://athenasc.com/probbook.html)

### Chap. 1: Sample Space and Probability
* 1.1 Sets
* 1.2 Probabilistic Models
* 1.3 Conditional Probability
* 1.4 Total Probability Theorem and Bayes' Rule
* 1.5 Independence
* 1.6 Counting
### Chap. 2: Discrete Random Variables
* Basic Concepts
* Probability Mass Functions
* Functions of Random Variables
* Expectation, Mean, and Variance
* Joint PMFs of Multiple Random Variables
* Conditioning
* Independence
### Chap. 3: General Random Variables
* Continuous Random Variables and PDFs
* Cumulative Distribution Functions
* Normal Random Variables
* Joint PDFs of Multiple Random Variables
* Conditioning
* The Continuous Bayes' Rule
### Chap. 4. Further Topics on Random Variables
* Derived Distributions
* Covariance and Correlation
* Conditional Expectation and Variance Revisited
* Transforms
* Sums of Independent Random Variables - Convolution
* Sum of a Random Number of Independent Random Variables
### Chap. 5. Limit Theorems
* Markov and Chebyshev Inequalities
* The Weak Law of Large Numbers
* Convergence in Probability
* The Central Limit Theorem
* The Strong Law of Large Numbers
### Chap. 6. The Bernoulli and Poisson Processes
* The Bernoulli Process
* The Poisson Process
### Chap. 7. Markov Chains
* Discrete-Time Markov Chains
* Classification of States
* Steady-State Behavior
* Absorption Probabilities and Expected Time to Absorption
* Continuous-Time Markov Chains
### Chap. 8. Bayesian Statistical Inference
* Bayesian Inference and the Posterior Distribution
* Point Estimation, Hypothesis Testing, and the MAP Rule
* Bayesian Least Mean Squares Estimation
* Bayesian Linear Least Mean Squares Estimation
### Chap. 9. Classical Statistical Inference
* Classical Parameter Estimation
* Linear Regression
* Binary Hypothesis Testing
* Significance Testing


